{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE_ML_2020_01_30_CE_ML_StyleTransfer_Sashi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIPzNGgNqs0bLVhgOTwovK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semant/MachineLearning/blob/master/DeepLearning_StyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abG33IZ5pDJt",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning: Using Neural Style Transfer for Image Manipulation\n",
        "\n",
        "> Semant Jain, PhD\n",
        "> semant@gmail.com\n",
        "\n",
        "### Summary\n",
        "> Image stylization refers to a class of machine learning algorithms which combine two photographs -- an artwork depicting a photo and a transformation that could be learned -- to create a new artwork. This process creates artificial artwork.\n",
        "\n",
        "> Normally, in computer vision, a convolutional neural network extracts features from a single layer. In style transfer, this process is maintained for a content image. However, to analyze the style image, the neural network examines the relationships between the layers. \n",
        "\n",
        "> In this project, to create artificial artwork, a deep convolutional neural network - with pretrained weights (VGG19) was used. Limitations on use of Google Colaboratory only permitted 2000 iterations to be conducted. \n",
        "\n",
        "\n",
        "### Contents\n",
        "\n",
        "\n",
        "### Libraries\n",
        "+ Keras\n",
        "+ Numpy\n",
        "+ PIL\n",
        "+ Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPvoXvYQtjYC",
        "colab_type": "code",
        "outputId": "f14aeec3-b372-48df-b575-7513b55e37c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "\n",
        "# Keras is only used to load VGG19 model as a high level API to TensorFlow \n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "# pillow is used for loading and saving images\n",
        "from PIL import Image\n",
        "\n",
        "# numPy is used for manipulation of array of object i.e Image in our case\n",
        "import numpy as np\n",
        "\n",
        "##\n",
        "##\n",
        "##\n",
        "\n",
        "# list of layers to be considered for calculation of Content and Style Loss\n",
        "content_layers = ['block3_conv3']\n",
        "style_layers   = ['block1_conv1','block2_conv2','block4_conv3']\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers   = len(style_layers)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjofcym1N3O3",
        "colab_type": "code",
        "outputId": "e9cbc16a-d3ba-4daf-bbfe-d0793e9091df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# path where the content and style images are located\n",
        "# ENSURE THAT THE FILE NAMES ARE THE SAME\n",
        "# ENSURE THAT THE FILES ARE UPLOADED IN THE ROOT FOLDER\n",
        "content_path = 'Content.jpeg'\n",
        "style_path   = 'Style.jpeg'\n",
        "\n",
        "# Save the result as\n",
        "save_name = 'generated.jpg'\n",
        "\n",
        "# DOWNLOAD WEIGHTS AND ENSURE THAT THE NAME MATCHES THE NAME BELOW AND MOVE TO FOLDER (vgg_weights/)\n",
        "!wget https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5 -P vgg_weights/\n",
        "\n",
        "# path to where Vgg19 model weight is located \n",
        "vgg_weights = \"vgg_weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "\n",
        "\n",
        "\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "#                                        UTILS\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "\n",
        "def load_img(path_to_img):\n",
        "\n",
        "  max_dim  = 512\n",
        "  img      = Image.open(path_to_img)\n",
        "  img_size = max(img.size)\n",
        "  scale    = max_dim/img_size\n",
        "  img      = img.resize((round(img.size[0]*scale), round(img.size[1]*scale)), Image.ANTIALIAS)\n",
        "\n",
        "  img      = kp_image.img_to_array(img)\n",
        "\n",
        "  # We need to broadcast the image array such that it has a batch dimension \n",
        "  img = np.expand_dims(img, axis=0)\n",
        "\n",
        "  # preprocess raw images to make it suitable to be used by VGG19 model\n",
        "  out = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "\n",
        "  return tf.convert_to_tensor(out)\n",
        "\n",
        "def deprocess_img(processed_img):\n",
        "  x = processed_img.copy()\n",
        "  \n",
        "  # perform the inverse of the preprocessiing step\n",
        "  x[:, :, 0] += 103.939\n",
        "  x[:, :, 1] += 116.779\n",
        "  x[:, :, 2] += 123.68\n",
        "\n",
        "  x = x[:, :, ::-1]\n",
        "\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "\n",
        "  return x\n",
        "\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "#                                        Loss Function\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "\n",
        "### Content Loss Function\n",
        "def get_content_loss(content, target):\n",
        "  return tf.reduce_mean(tf.square(content - target)) /2\n",
        "\n",
        "\n",
        "### Style Loss Fucntion\n",
        "def gram_matrix(input_tensor):\n",
        "\n",
        "  # if input tensor is a 3D array of size Nh x Nw X Nc\n",
        "  # we reshape it to a 2D array of Nc x (Nh*Nw)\n",
        "  channels = int(input_tensor.shape[-1])\n",
        "  a = tf.reshape(input_tensor, [-1, channels])\n",
        "  n = tf.shape(a)[0]\n",
        "\n",
        "  # get gram matrix \n",
        "  gram = tf.matmul(a, a, transpose_a=True)\n",
        "  \n",
        "  return gram\n",
        "\n",
        "def get_style_loss(base_style, gram_target):\n",
        "\n",
        "  height, width, channels = base_style.get_shape().as_list()\n",
        "  gram_style = gram_matrix(base_style)\n",
        "  \n",
        "  # Original eqn as a constant to divide i.e 1/(4. * (channels ** 2) * (width * height) ** 2)\n",
        "  return tf.reduce_mean(tf.square(gram_style - gram_target)) / (channels**2 * width * height) #(4.0 * (channels ** 2) * (width * height) ** 2)\n",
        "\n",
        "\n",
        "\n",
        "### Use to pass content and style image through it \n",
        "def get_feature_representations(model, content_path, style_path, num_content_layers):\n",
        "\n",
        "  # Load our images in \n",
        "  content_image = load_img(content_path)\n",
        "  style_image   = load_img(style_path)\n",
        "  \n",
        "  # batch compute content and style features\n",
        "  content_outputs = model(content_image)\n",
        "  style_outputs   = model(style_image)\n",
        "  \n",
        "  # Get the style and content feature representations from our model  \n",
        "  style_features   = [ style_layer[0]  for style_layer    in style_outputs[num_content_layers:] ]\n",
        "  content_features = [ content_layer[0] for content_layer in content_outputs[:num_content_layers] ]\n",
        "\n",
        "  return style_features, content_features\n",
        "\n",
        "\n",
        "### Total Loss\n",
        "def compute_loss(model, loss_weights, generated_output_activations, gram_style_features, content_features, num_content_layers, num_style_layers):\n",
        "\n",
        "  generated_content_activations = generated_output_activations[:num_content_layers]\n",
        "  generated_style_activations   = generated_output_activations[num_content_layers:]\n",
        "\n",
        "  style_weight, content_weight = loss_weights\n",
        "  \n",
        "  style_score = 0\n",
        "  content_score = 0\n",
        "\n",
        "  # Accumulate style losses from all layers\n",
        "  # Here, we equally weight each contribution of each loss layer\n",
        "  weight_per_style_layer = 1.0 / float(num_style_layers)\n",
        "  for target_style, comb_style in zip(gram_style_features, generated_style_activations):\n",
        "    temp = get_style_loss(comb_style[0], target_style)\n",
        "    style_score += weight_per_style_layer * temp\n",
        "    \n",
        "  # Accumulate content losses from all layers \n",
        "  weight_per_content_layer = 1.0 / float(num_content_layers)\n",
        "  for target_content, comb_content in zip(content_features, generated_content_activations):\n",
        "    temp = get_content_loss(comb_content[0], target_content)\n",
        "    content_score += weight_per_content_layer* temp\n",
        "\n",
        "  # Get total loss\n",
        "  loss = style_weight*style_score + content_weight*content_score \n",
        "\n",
        "\n",
        "  return loss, style_score, content_score\n",
        "\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "#                                    CREATE STYLE TRANFER\n",
        "############################################################################################################\n",
        "############################################################################################################\n",
        "\n",
        "\n",
        "# Using Keras Load VGG19 model\n",
        "def get_model(content_layers,style_layers):\n",
        "\n",
        "  # Load our model. We load pretrained VGG, trained on imagenet data\n",
        "  vgg19           = VGG19(weights=None, include_top=False)\n",
        "\n",
        "  # We don't need to (or want to) train any layers of our pre-trained vgg model, so we set it's trainable to false.\n",
        "  vgg19.trainable = False\n",
        "\n",
        "  style_model_outputs   =  [vgg19.get_layer(name).output for name in style_layers]\n",
        "  content_model_outputs =  [vgg19.get_layer(name).output for name in content_layers]\n",
        "  \n",
        "  model_outputs = content_model_outputs + style_model_outputs\n",
        "\n",
        "  # Build model \n",
        "  return Model(inputs = vgg19.input, outputs = model_outputs),  vgg19\n",
        "\n",
        "\n",
        "def run_style_transfer(content_path, style_path, num_iterations=1000, content_weight=0.1, style_weight=0.9): \n",
        "\n",
        "  # Create a tensorflow session \n",
        "  sess = tf.Session()\n",
        "\n",
        "  # Assign keras back-end to the TF session which we created\n",
        "  K.set_session(sess)\n",
        "\n",
        "  model, vgg19 = get_model(content_layers,style_layers)\n",
        "\n",
        "  # Get the style and content feature representations (from our specified intermediate layers) \n",
        "  style_features, content_features = get_feature_representations(model, content_path, style_path, num_content_layers)\n",
        "  gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n",
        "\n",
        "  # VGG default normalization\n",
        "  norm_means = np.array([103.939, 116.779, 123.68])\n",
        "  min_vals = -norm_means\n",
        "  max_vals = 255 - norm_means \n",
        "    \n",
        "\n",
        "  # In original paper, the initial stylized image is random matrix of same size as that of content image\n",
        "  # but in later images content image was used instead on random values for first stylized image\n",
        "  # because it proved to help to stylize faster\n",
        "  generated_image = load_img(content_path)\n",
        "  # generated_image = np.random.randint(0,255, size=generated_image.shape) \n",
        "  \n",
        "  # Create tensorflow variable to hold a stylized/generated image during the training \n",
        "  generated_image = tf.Variable(generated_image, dtype=tf.float32)\n",
        "\n",
        "  model_outputs = model(generated_image)\n",
        "\n",
        "  # weightages of each content and style images i.e alpha & beta\n",
        "  loss_weights = (style_weight, content_weight)\n",
        "\n",
        "  # Create our optimizer\n",
        "  loss = compute_loss(model, loss_weights, model_outputs, gram_style_features, content_features, num_content_layers, num_style_layers)\n",
        "  opt = tf.train.AdamOptimizer(learning_rate=9, beta1=0.9, epsilon=1e-1).minimize( loss[0], var_list = [generated_image])\n",
        "\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(generated_image.initializer)\n",
        "  \n",
        "  # loading the weights again because tf.global_variables_initializer() resets the weights\n",
        "  vgg19.load_weights(vgg_weights)\n",
        "\n",
        "\n",
        "  # Put loss as infinity before training starts and Create a variable to hold best image (i.e image with minimum loss)\n",
        "  best_loss, best_img = float('inf'), None\n",
        "\n",
        "  for i in range(num_iterations):\n",
        "\n",
        "    # Do optimization\n",
        "    sess.run(opt)\n",
        "\n",
        "    # Make sure image values stays in the range of max-min value of VGG norm \n",
        "    clipped = tf.clip_by_value(generated_image, min_vals, max_vals)\n",
        "    # assign the clipped value to the tensor stylized image\n",
        "    generated_image.assign(clipped)\n",
        "\n",
        "\n",
        "    # Open the Tuple of tensors \n",
        "    total_loss, style_score, content_score = loss\n",
        "    total_loss = total_loss.eval(session=sess)\n",
        "\n",
        "\n",
        "    if total_loss < best_loss:\n",
        "\n",
        "      # Update best loss and best image from total loss. \n",
        "      best_loss = total_loss\n",
        "\n",
        "      # generated image is of shape (1, h, w, 3) convert it to (h, w, 3)\n",
        "      temp_generated_image = sess.run(generated_image)[0]\n",
        "      best_img = deprocess_img(temp_generated_image)\n",
        "\n",
        "      s_loss = sess.run(style_score)\n",
        "      c_loss = sess.run(content_score)\n",
        "\n",
        "      # print best loss\n",
        "      print('best: iteration: ', i ,'loss: ', total_loss ,'  style_loss: ',  s_loss,'  content_loss: ', c_loss)\n",
        "\n",
        "    # Save image after every 100 iterations \n",
        "    if (i+1)%100 == 0:\n",
        "      output = Image.fromarray(best_img)\n",
        "      output.save(str(i+1)+'-'+save_name)\n",
        "\n",
        "  # after num_iterations iterations are completed, close the TF session \n",
        "  sess.close()\n",
        "      \n",
        "  return best_img, best_loss\n",
        "\n",
        "best, best_loss = run_style_transfer(content_path, style_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-08 11:49:02--  https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/64878964/b0a81400-5983-11e6-8d11-beae6f3297b5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200208%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200208T114908Z&X-Amz-Expires=300&X-Amz-Signature=a96c7e49de90720730c68dca908fb808c6ebb17176fbb3cd705d2f8582bd7c76&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dvgg19_weights_tf_dim_ordering_tf_kernels_notop.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-02-08 11:49:08--  https://github-production-release-asset-2e65be.s3.amazonaws.com/64878964/b0a81400-5983-11e6-8d11-beae6f3297b5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200208%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200208T114908Z&X-Amz-Expires=300&X-Amz-Signature=a96c7e49de90720730c68dca908fb808c6ebb17176fbb3cd705d2f8582bd7c76&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dvgg19_weights_tf_dim_ordering_tf_kernels_notop.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.171.147\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.171.147|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80134624 (76M) [application/octet-stream]\n",
            "Saving to: ‘vgg_weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "vgg19_weights_tf_di 100%[===================>]  76.42M  83.3MB/s    in 0.9s    \n",
            "\n",
            "2020-02-08 11:49:09 (83.3 MB/s) - ‘vgg_weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [80134624/80134624]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "best: iteration:  0 loss:  94419460.0   style_loss:  104907816.0   content_loss:  24271.312\n",
            "best: iteration:  1 loss:  68712456.0   style_loss:  76342610.0   content_loss:  41117.65\n",
            "best: iteration:  2 loss:  53141730.0   style_loss:  59040704.0   content_loss:  50970.324\n",
            "best: iteration:  3 loss:  40084970.0   style_loss:  44532644.0   content_loss:  55874.47\n",
            "best: iteration:  4 loss:  28669492.0   style_loss:  31848516.0   content_loss:  58279.43\n",
            "best: iteration:  5 loss:  21068686.0   style_loss:  23403018.0   content_loss:  59704.164\n",
            "best: iteration:  6 loss:  16576942.0   style_loss:  18412056.0   content_loss:  60922.547\n",
            "best: iteration:  7 loss:  13568715.0   style_loss:  15069419.0   content_loss:  62383.84\n",
            "best: iteration:  8 loss:  11438196.0   style_loss:  12701974.0   content_loss:  64204.617\n",
            "best: iteration:  9 loss:  10131386.0   style_loss:  11249749.0   content_loss:  66115.05\n",
            "best: iteration:  10 loss:  9179752.0   style_loss:  10192199.0   content_loss:  67728.555\n",
            "best: iteration:  11 loss:  8197736.0   style_loss:  9100941.0   content_loss:  68897.22\n",
            "best: iteration:  12 loss:  7293079.5   style_loss:  8095669.5   content_loss:  69771.01\n",
            "best: iteration:  13 loss:  6620125.5   style_loss:  7347856.0   content_loss:  70553.164\n",
            "best: iteration:  14 loss:  6108567.5   style_loss:  6779361.5   content_loss:  71424.555\n",
            "best: iteration:  15 loss:  5654799.0   style_loss:  6275064.5   content_loss:  72410.19\n",
            "best: iteration:  16 loss:  5252232.0   style_loss:  5827655.0   content_loss:  73426.28\n",
            "best: iteration:  17 loss:  4918335.5   style_loss:  5456559.0   content_loss:  74322.766\n",
            "best: iteration:  18 loss:  4630842.0   style_loss:  5137045.0   content_loss:  75017.21\n",
            "best: iteration:  19 loss:  4362260.5   style_loss:  4838563.0   content_loss:  75541.44\n",
            "best: iteration:  20 loss:  4111077.8   style_loss:  4559422.0   content_loss:  75980.19\n",
            "best: iteration:  21 loss:  3873276.8   style_loss:  4295149.0   content_loss:  76427.93\n",
            "best: iteration:  22 loss:  3640079.2   style_loss:  4035982.0   content_loss:  76953.96\n",
            "best: iteration:  23 loss:  3420811.8   style_loss:  3792283.2   content_loss:  77570.94\n",
            "best: iteration:  24 loss:  3228281.0   style_loss:  3578288.5   content_loss:  78215.97\n",
            "best: iteration:  25 loss:  3049993.8   style_loss:  3380124.2   content_loss:  78819.305\n",
            "best: iteration:  26 loss:  2873085.2   style_loss:  3183502.8   content_loss:  79326.71\n",
            "best: iteration:  27 loss:  2703415.5   style_loss:  2994936.2   content_loss:  79730.695\n",
            "best: iteration:  28 loss:  2541469.2   style_loss:  2814957.8   content_loss:  80071.55\n",
            "best: iteration:  29 loss:  2379651.0   style_loss:  2635123.2   content_loss:  80402.62\n",
            "best: iteration:  30 loss:  2219298.8   style_loss:  2456912.8   content_loss:  80771.87\n",
            "best: iteration:  31 loss:  2068769.4   style_loss:  2289612.2   content_loss:  81183.59\n",
            "best: iteration:  32 loss:  1928093.1   style_loss:  2133260.2   content_loss:  81590.04\n",
            "best: iteration:  33 loss:  1790439.0   style_loss:  1980270.9   content_loss:  81952.38\n",
            "best: iteration:  34 loss:  1658610.5   style_loss:  1833760.2   content_loss:  82264.25\n",
            "best: iteration:  35 loss:  1540939.0   style_loss:  1702981.6   content_loss:  82555.914\n",
            "best: iteration:  36 loss:  1435635.5   style_loss:  1585944.5   content_loss:  82855.08\n",
            "best: iteration:  37 loss:  1337869.2   style_loss:  1477281.1   content_loss:  83162.19\n",
            "best: iteration:  38 loss:  1248271.0   style_loss:  1377695.6   content_loss:  83450.23\n",
            "best: iteration:  39 loss:  1167719.6   style_loss:  1288167.5   content_loss:  83688.15\n",
            "best: iteration:  40 loss:  1094873.9   style_loss:  1207207.6   content_loss:  83869.62\n",
            "best: iteration:  41 loss:  1028598.75   style_loss:  1133551.9   content_loss:  84020.484\n",
            "best: iteration:  42 loss:  968892.4   style_loss:  1067194.8   content_loss:  84171.22\n",
            "best: iteration:  43 loss:  914776.4   style_loss:  1007047.5   content_loss:  84336.37\n",
            "best: iteration:  44 loss:  865441.25   style_loss:  952211.0   content_loss:  84513.84\n",
            "best: iteration:  45 loss:  821373.9   style_loss:  903228.3   content_loss:  84684.53\n",
            "best: iteration:  46 loss:  781678.56   style_loss:  859106.3   content_loss:  84828.625\n",
            "best: iteration:  47 loss:  745397.56   style_loss:  818782.06   content_loss:  84937.2\n",
            "best: iteration:  48 loss:  712867.3   style_loss:  782628.3   content_loss:  85018.75\n",
            "best: iteration:  49 loss:  683283.0   style_loss:  749747.9   content_loss:  85099.42\n",
            "best: iteration:  50 loss:  655239.7   style_loss:  718577.5   content_loss:  85199.555\n",
            "best: iteration:  51 loss:  629054.5   style_loss:  689469.4   content_loss:  85320.625\n",
            "best: iteration:  52 loss:  605415.5   style_loss:  663190.4   content_loss:  85442.16\n",
            "best: iteration:  53 loss:  583184.25   style_loss:  638478.06   content_loss:  85540.13\n",
            "best: iteration:  54 loss:  561598.8   style_loss:  614486.75   content_loss:  85607.31\n",
            "best: iteration:  55 loss:  541461.5   style_loss:  592105.9   content_loss:  85662.51\n",
            "best: iteration:  56 loss:  522508.6   style_loss:  571039.7   content_loss:  85728.75\n",
            "best: iteration:  57 loss:  503927.56   style_loss:  550384.94   content_loss:  85811.15\n",
            "best: iteration:  58 loss:  486102.62   style_loss:  530569.9   content_loss:  85897.4\n",
            "best: iteration:  59 loss:  469474.34   style_loss:  512085.2   content_loss:  85976.96\n",
            "best: iteration:  60 loss:  453530.0   style_loss:  494361.16   content_loss:  86049.58\n",
            "best: iteration:  61 loss:  438064.62   style_loss:  477169.06   content_loss:  86124.766\n",
            "best: iteration:  62 loss:  423443.1   style_loss:  460913.53   content_loss:  86209.305\n",
            "best: iteration:  63 loss:  409622.03   style_loss:  445546.34   content_loss:  86303.34\n",
            "best: iteration:  64 loss:  396419.6   style_loss:  430866.34   content_loss:  86398.93\n",
            "best: iteration:  65 loss:  383789.66   style_loss:  416823.4   content_loss:  86485.984\n",
            "best: iteration:  66 loss:  371809.8   style_loss:  403504.5   content_loss:  86557.88\n",
            "best: iteration:  67 loss:  360592.12   style_loss:  391033.75   content_loss:  86617.555\n",
            "best: iteration:  68 loss:  350016.5   style_loss:  379276.56   content_loss:  86676.06\n",
            "best: iteration:  69 loss:  339922.53   style_loss:  368053.5   content_loss:  86743.9\n",
            "best: iteration:  70 loss:  330450.97   style_loss:  357521.38   content_loss:  86817.414\n",
            "best: iteration:  71 loss:  321607.56   style_loss:  347687.94   content_loss:  86884.28\n",
            "best: iteration:  72 loss:  313085.88   style_loss:  338213.53   content_loss:  86937.11\n",
            "best: iteration:  73 loss:  304982.88   style_loss:  329205.2   content_loss:  86982.2\n",
            "best: iteration:  74 loss:  297445.6   style_loss:  320824.94   content_loss:  87031.42\n",
            "best: iteration:  75 loss:  290246.72   style_loss:  312819.75   content_loss:  87089.305\n",
            "best: iteration:  76 loss:  283310.88   style_loss:  305106.47   content_loss:  87150.66\n",
            "best: iteration:  77 loss:  276760.03   style_loss:  297821.44   content_loss:  87207.484\n",
            "best: iteration:  78 loss:  270519.8   style_loss:  290882.5   content_loss:  87255.52\n",
            "best: iteration:  79 loss:  264531.84   style_loss:  284224.66   content_loss:  87296.484\n",
            "best: iteration:  80 loss:  258819.89   style_loss:  277873.78   content_loss:  87335.016\n",
            "best: iteration:  81 loss:  253347.97   style_loss:  271789.38   content_loss:  87375.32\n",
            "best: iteration:  82 loss:  248102.92   style_loss:  265956.88   content_loss:  87417.34\n",
            "best: iteration:  83 loss:  243071.23   style_loss:  260361.75   content_loss:  87456.66\n",
            "best: iteration:  84 loss:  238234.3   style_loss:  254983.78   content_loss:  87489.02\n",
            "best: iteration:  85 loss:  233608.1   style_loss:  249840.44   content_loss:  87517.11\n",
            "best: iteration:  86 loss:  229154.98   style_loss:  244889.19   content_loss:  87547.18\n",
            "best: iteration:  87 loss:  224843.95   style_loss:  240095.38   content_loss:  87581.25\n",
            "best: iteration:  88 loss:  220713.05   style_loss:  235501.69   content_loss:  87615.32\n",
            "best: iteration:  89 loss:  216735.06   style_loss:  231078.5   content_loss:  87644.16\n",
            "best: iteration:  90 loss:  212881.34   style_loss:  226793.84   content_loss:  87668.984\n",
            "best: iteration:  91 loss:  209179.11   style_loss:  222677.4   content_loss:  87694.53\n",
            "best: iteration:  92 loss:  205605.33   style_loss:  218703.28   content_loss:  87723.82\n",
            "best: iteration:  93 loss:  202146.42   style_loss:  214856.39   content_loss:  87756.77\n",
            "best: iteration:  94 loss:  198819.3   style_loss:  211155.88   content_loss:  87790.18\n",
            "best: iteration:  95 loss:  195604.16   style_loss:  207580.1   content_loss:  87820.82\n",
            "best: iteration:  96 loss:  192492.16   style_loss:  204119.33   content_loss:  87847.66\n",
            "best: iteration:  97 loss:  189484.92   style_loss:  200775.12   content_loss:  87873.06\n",
            "best: iteration:  98 loss:  186574.8   style_loss:  197538.61   content_loss:  87900.414\n",
            "best: iteration:  99 loss:  183760.64   style_loss:  194408.48   content_loss:  87930.086\n",
            "best: iteration:  100 loss:  181035.4   style_loss:  191377.22   content_loss:  87959.14\n",
            "best: iteration:  101 loss:  178392.48   style_loss:  188437.72   content_loss:  87985.414\n",
            "best: iteration:  102 loss:  175832.05   style_loss:  185590.06   content_loss:  88010.04\n",
            "best: iteration:  103 loss:  173348.1   style_loss:  182827.31   content_loss:  88035.15\n",
            "best: iteration:  104 loss:  170940.4   style_loss:  180149.22   content_loss:  88061.13\n",
            "best: iteration:  105 loss:  168605.4   style_loss:  177551.95   content_loss:  88086.62\n",
            "best: iteration:  106 loss:  166333.89   style_loss:  175025.31   content_loss:  88111.04\n",
            "best: iteration:  107 loss:  164129.47   style_loss:  172573.33   content_loss:  88134.84\n",
            "best: iteration:  108 loss:  161989.16   style_loss:  170192.56   content_loss:  88158.62\n",
            "best: iteration:  109 loss:  159905.45   style_loss:  167874.72   content_loss:  88182.08\n",
            "best: iteration:  110 loss:  157881.17   style_loss:  165622.97   content_loss:  88204.984\n",
            "best: iteration:  111 loss:  155911.56   style_loss:  163432.05   content_loss:  88227.13\n",
            "best: iteration:  112 loss:  153992.67   style_loss:  161297.61   content_loss:  88248.27\n",
            "best: iteration:  113 loss:  152125.0   style_loss:  159220.06   content_loss:  88269.56\n",
            "best: iteration:  114 loss:  150306.38   style_loss:  157196.88   content_loss:  88291.914\n",
            "best: iteration:  115 loss:  148533.89   style_loss:  155224.97   content_loss:  88314.24\n",
            "best: iteration:  116 loss:  146807.69   style_loss:  153304.64   content_loss:  88335.18\n",
            "best: iteration:  117 loss:  145127.1   style_loss:  151435.14   content_loss:  88354.75\n",
            "best: iteration:  118 loss:  143489.53   style_loss:  149613.45   content_loss:  88374.164\n",
            "best: iteration:  119 loss:  141891.64   style_loss:  147835.77   content_loss:  88394.47\n",
            "best: iteration:  120 loss:  140333.25   style_loss:  146101.9   content_loss:  88415.234\n",
            "best: iteration:  121 loss:  138812.66   style_loss:  144410.14   content_loss:  88435.375\n",
            "best: iteration:  122 loss:  137327.47   style_loss:  142757.78   content_loss:  88454.734\n",
            "best: iteration:  123 loss:  135878.45   style_loss:  141145.62   content_loss:  88473.87\n",
            "best: iteration:  124 loss:  134463.56   style_loss:  139571.36   content_loss:  88493.484\n",
            "best: iteration:  125 loss:  133081.06   style_loss:  138032.97   content_loss:  88513.87\n",
            "best: iteration:  126 loss:  131731.44   style_loss:  136531.16   content_loss:  88534.055\n",
            "best: iteration:  127 loss:  130412.75   style_loss:  135063.81   content_loss:  88553.164\n",
            "best: iteration:  128 loss:  129123.66   style_loss:  133629.45   content_loss:  88571.484\n",
            "best: iteration:  129 loss:  127863.5   style_loss:  132227.2   content_loss:  88590.266\n",
            "best: iteration:  130 loss:  126631.125   style_loss:  130855.72   content_loss:  88609.81\n",
            "best: iteration:  131 loss:  125426.06   style_loss:  129514.6   content_loss:  88629.18\n",
            "best: iteration:  132 loss:  124246.56   style_loss:  128201.984   content_loss:  88647.82\n",
            "best: iteration:  133 loss:  123092.484   style_loss:  126917.67   content_loss:  88665.87\n",
            "best: iteration:  134 loss:  121962.31   style_loss:  125659.92   content_loss:  88683.836\n",
            "best: iteration:  135 loss:  120855.766   style_loss:  124428.39   content_loss:  88702.23\n",
            "best: iteration:  136 loss:  119771.93   style_loss:  123222.06   content_loss:  88720.76\n",
            "best: iteration:  137 loss:  118710.34   style_loss:  122040.5   content_loss:  88738.984\n",
            "best: iteration:  138 loss:  117670.32   style_loss:  120882.95   content_loss:  88756.63\n",
            "best: iteration:  139 loss:  116651.234   style_loss:  119748.67   content_loss:  88774.29\n",
            "best: iteration:  140 loss:  115652.48   style_loss:  118636.95   content_loss:  88792.16\n",
            "best: iteration:  141 loss:  114673.21   style_loss:  117546.94   content_loss:  88809.72\n",
            "best: iteration:  142 loss:  113712.15   style_loss:  116477.2   content_loss:  88826.72\n",
            "best: iteration:  143 loss:  112768.84   style_loss:  115427.22   content_loss:  88843.5\n",
            "best: iteration:  144 loss:  111843.375   style_loss:  114397.055   content_loss:  88860.32\n",
            "best: iteration:  145 loss:  110934.86   style_loss:  113385.7   content_loss:  88877.25\n",
            "best: iteration:  146 loss:  110043.03   style_loss:  112392.94   content_loss:  88893.92\n",
            "best: iteration:  147 loss:  109167.336   style_loss:  111418.13   content_loss:  88910.14\n",
            "best: iteration:  148 loss:  108307.36   style_loss:  110460.84   content_loss:  88926.016\n",
            "best: iteration:  149 loss:  107462.984   style_loss:  109520.91   content_loss:  88941.75\n",
            "best: iteration:  150 loss:  106633.91   style_loss:  108597.96   content_loss:  88957.42\n",
            "best: iteration:  151 loss:  105819.12   style_loss:  107690.93   content_loss:  88972.81\n",
            "best: iteration:  152 loss:  105018.48   style_loss:  106799.7   content_loss:  88987.53\n",
            "best: iteration:  153 loss:  104231.86   style_loss:  105924.11   content_loss:  89001.68\n",
            "best: iteration:  154 loss:  103459.01   style_loss:  105063.81   content_loss:  89015.77\n",
            "best: iteration:  155 loss:  102699.63   style_loss:  104218.5   content_loss:  89029.87\n",
            "best: iteration:  156 loss:  101953.17   style_loss:  103387.56   content_loss:  89043.63\n",
            "best: iteration:  157 loss:  101219.53   style_loss:  102570.92   content_loss:  89057.07\n",
            "best: iteration:  158 loss:  100498.17   style_loss:  101767.97   content_loss:  89070.03\n",
            "best: iteration:  159 loss:  99788.91   style_loss:  100978.47   content_loss:  89082.91\n",
            "best: iteration:  160 loss:  99091.03   style_loss:  100201.59   content_loss:  89095.99\n",
            "best: iteration:  161 loss:  98403.9   style_loss:  99436.66   content_loss:  89109.11\n",
            "best: iteration:  162 loss:  97727.74   style_loss:  98683.92   content_loss:  89122.16\n",
            "best: iteration:  163 loss:  97062.42   style_loss:  97943.22   content_loss:  89135.26\n",
            "best: iteration:  164 loss:  96407.42   style_loss:  97213.984   content_loss:  89148.39\n",
            "best: iteration:  165 loss:  95762.42   style_loss:  96495.84   content_loss:  89161.63\n",
            "best: iteration:  166 loss:  95126.94   style_loss:  95788.27   content_loss:  89174.91\n",
            "best: iteration:  167 loss:  94500.625   style_loss:  95090.91   content_loss:  89188.09\n",
            "best: iteration:  168 loss:  93883.67   style_loss:  94403.94   content_loss:  89201.34\n",
            "best: iteration:  169 loss:  93275.914   style_loss:  93727.16   content_loss:  89214.78\n",
            "best: iteration:  170 loss:  92677.61   style_loss:  93060.875   content_loss:  89228.24\n",
            "best: iteration:  171 loss:  92088.17   style_loss:  92404.49   content_loss:  89241.33\n",
            "best: iteration:  172 loss:  91507.56   style_loss:  91757.97   content_loss:  89253.914\n",
            "best: iteration:  173 loss:  90936.08   style_loss:  91121.62   content_loss:  89266.25\n",
            "best: iteration:  174 loss:  90373.086   style_loss:  90494.72   content_loss:  89278.414\n",
            "best: iteration:  175 loss:  89818.21   style_loss:  89876.86   content_loss:  89290.39\n",
            "best: iteration:  176 loss:  89271.484   style_loss:  89268.055   content_loss:  89302.32\n",
            "best: iteration:  177 loss:  88732.93   style_loss:  88668.336   content_loss:  89314.32\n",
            "best: iteration:  178 loss:  88201.72   style_loss:  88076.76   content_loss:  89326.39\n",
            "best: iteration:  179 loss:  87677.875   style_loss:  87493.36   content_loss:  89338.49\n",
            "best: iteration:  180 loss:  87161.47   style_loss:  86918.26   content_loss:  89350.41\n",
            "best: iteration:  181 loss:  86652.11   style_loss:  86351.0   content_loss:  89362.12\n",
            "best: iteration:  182 loss:  86150.15   style_loss:  85791.984   content_loss:  89373.64\n",
            "best: iteration:  183 loss:  85655.086   style_loss:  85240.64   content_loss:  89385.08\n",
            "best: iteration:  184 loss:  85167.27   style_loss:  84697.375   content_loss:  89396.38\n",
            "best: iteration:  185 loss:  84686.2   style_loss:  84161.59   content_loss:  89407.7\n",
            "best: iteration:  186 loss:  84211.7   style_loss:  83633.11   content_loss:  89419.04\n",
            "best: iteration:  187 loss:  83743.97   style_loss:  83112.14   content_loss:  89430.44\n",
            "best: iteration:  188 loss:  83282.8   style_loss:  82598.46   content_loss:  89441.9\n",
            "best: iteration:  189 loss:  82827.68   style_loss:  82091.484   content_loss:  89453.46\n",
            "best: iteration:  190 loss:  82378.695   style_loss:  81591.34   content_loss:  89464.87\n",
            "best: iteration:  191 loss:  81935.98   style_loss:  81098.19   content_loss:  89476.08\n",
            "best: iteration:  192 loss:  81498.97   style_loss:  80611.39   content_loss:  89487.21\n",
            "best: iteration:  193 loss:  81067.79   style_loss:  80131.08   content_loss:  89498.19\n",
            "best: iteration:  194 loss:  80642.31   style_loss:  79657.125   content_loss:  89508.96\n",
            "best: iteration:  195 loss:  80222.336   style_loss:  79189.33   content_loss:  89519.47\n",
            "best: iteration:  196 loss:  79807.72   style_loss:  78727.49   content_loss:  89529.79\n",
            "best: iteration:  197 loss:  79398.55   style_loss:  78271.72   content_loss:  89539.984\n",
            "best: iteration:  198 loss:  78994.59   style_loss:  77821.75   content_loss:  89550.266\n",
            "best: iteration:  199 loss:  78596.11   style_loss:  77377.836   content_loss:  89560.586\n",
            "best: iteration:  200 loss:  78202.88   style_loss:  76939.78   content_loss:  89570.77\n",
            "best: iteration:  201 loss:  77814.87   style_loss:  76507.555   content_loss:  89580.734\n",
            "best: iteration:  202 loss:  77431.73   style_loss:  76080.75   content_loss:  89590.55\n",
            "best: iteration:  203 loss:  77053.414   style_loss:  75659.32   content_loss:  89600.32\n",
            "best: iteration:  204 loss:  76679.83   style_loss:  75243.13   content_loss:  89610.12\n",
            "best: iteration:  205 loss:  76310.83   style_loss:  74832.06   content_loss:  89619.77\n",
            "best: iteration:  206 loss:  75946.39   style_loss:  74426.07   content_loss:  89629.29\n",
            "best: iteration:  207 loss:  75586.68   style_loss:  74025.34   content_loss:  89638.75\n",
            "best: iteration:  208 loss:  75231.56   style_loss:  73629.72   content_loss:  89648.2\n",
            "best: iteration:  209 loss:  74880.67   style_loss:  73238.805   content_loss:  89657.5\n",
            "best: iteration:  210 loss:  74533.86   style_loss:  72852.445   content_loss:  89666.68\n",
            "best: iteration:  211 loss:  74191.06   style_loss:  72470.53   content_loss:  89675.82\n",
            "best: iteration:  212 loss:  73852.445   style_loss:  72093.28   content_loss:  89684.9\n",
            "best: iteration:  213 loss:  73517.77   style_loss:  71720.41   content_loss:  89694.1\n",
            "best: iteration:  214 loss:  73187.1   style_loss:  71351.95   content_loss:  89703.44\n",
            "best: iteration:  215 loss:  72860.53   style_loss:  70988.05   content_loss:  89712.89\n",
            "best: iteration:  216 loss:  72537.78   style_loss:  70628.39   content_loss:  89722.336\n",
            "best: iteration:  217 loss:  72218.52   style_loss:  70272.61   content_loss:  89731.77\n",
            "best: iteration:  218 loss:  71903.04   style_loss:  69921.04   content_loss:  89741.03\n",
            "best: iteration:  219 loss:  71591.32   style_loss:  69573.664   content_loss:  89750.21\n",
            "best: iteration:  220 loss:  71283.26   style_loss:  69230.34   content_loss:  89759.47\n",
            "best: iteration:  221 loss:  70978.766   style_loss:  68891.016   content_loss:  89768.54\n",
            "best: iteration:  222 loss:  70677.625   style_loss:  68555.42   content_loss:  89777.44\n",
            "best: iteration:  223 loss:  70379.83   style_loss:  68223.58   content_loss:  89786.13\n",
            "best: iteration:  224 loss:  70085.25   style_loss:  67895.31   content_loss:  89794.66\n",
            "best: iteration:  225 loss:  69794.13   style_loss:  67570.9   content_loss:  89803.21\n",
            "best: iteration:  226 loss:  69506.41   style_loss:  67250.25   content_loss:  89811.875\n",
            "best: iteration:  227 loss:  69221.805   style_loss:  66933.06   content_loss:  89820.516\n",
            "best: iteration:  228 loss:  68940.4   style_loss:  66619.43   content_loss:  89829.17\n",
            "best: iteration:  229 loss:  68661.97   style_loss:  66309.1   content_loss:  89837.74\n",
            "best: iteration:  230 loss:  68386.27   style_loss:  66001.86   content_loss:  89846.04\n",
            "best: iteration:  231 loss:  68113.45   style_loss:  65697.83   content_loss:  89854.086\n",
            "best: iteration:  232 loss:  67843.516   style_loss:  65397.008   content_loss:  89862.086\n",
            "best: iteration:  233 loss:  67576.55   style_loss:  65099.48   content_loss:  89870.125\n",
            "best: iteration:  234 loss:  67312.336   style_loss:  64805.016   content_loss:  89878.266\n",
            "best: iteration:  235 loss:  67051.4   style_loss:  64514.18   content_loss:  89886.37\n",
            "best: iteration:  236 loss:  66794.0   style_loss:  64227.254   content_loss:  89894.76\n",
            "best: iteration:  237 loss:  66541.99   style_loss:  63946.34   content_loss:  89902.914\n",
            "best: iteration:  238 loss:  66298.84   style_loss:  63675.254   content_loss:  89911.2\n",
            "best: iteration:  239 loss:  66074.336   style_loss:  63424.938   content_loss:  89918.95\n",
            "best: iteration:  240 loss:  65893.195   style_loss:  63222.727   content_loss:  89927.44\n",
            "best: iteration:  241 loss:  65821.695   style_loss:  63142.46   content_loss:  89934.81\n",
            "best: iteration:  277 loss:  63546.258   style_loss:  60597.95   content_loss:  90081.04\n",
            "best: iteration:  280 loss:  63198.375   style_loss:  60204.21   content_loss:  90145.875\n",
            "best: iteration:  284 loss:  61454.242   style_loss:  58260.75   content_loss:  90195.7\n",
            "best: iteration:  287 loss:  60239.4   style_loss:  56907.797   content_loss:  90223.805\n",
            "best: iteration:  290 loss:  60075.473   style_loss:  56722.11   content_loss:  90255.73\n",
            "best: iteration:  291 loss:  59407.418   style_loss:  55976.375   content_loss:  90286.82\n",
            "best: iteration:  294 loss:  58433.023   style_loss:  54890.64   content_loss:  90314.484\n",
            "best: iteration:  297 loss:  58093.445   style_loss:  54509.58   content_loss:  90348.27\n",
            "best: iteration:  298 loss:  57444.164   style_loss:  53790.188   content_loss:  90329.98\n",
            "best: iteration:  301 loss:  56955.16   style_loss:  53244.098   content_loss:  90354.73\n",
            "best: iteration:  302 loss:  56494.22   style_loss:  52727.914   content_loss:  90390.96\n",
            "best: iteration:  303 loss:  56351.9   style_loss:  52570.84   content_loss:  90381.46\n",
            "best: iteration:  304 loss:  56311.82   style_loss:  52526.1   content_loss:  90383.32\n",
            "best: iteration:  305 loss:  56024.668   style_loss:  52203.46   content_loss:  90415.53\n",
            "best: iteration:  306 loss:  55554.254   style_loss:  51683.086   content_loss:  90394.77\n",
            "best: iteration:  307 loss:  55313.914   style_loss:  51413.867   content_loss:  90414.34\n",
            "best: iteration:  309 loss:  55175.227   style_loss:  51260.12   content_loss:  90411.164\n",
            "best: iteration:  310 loss:  54721.176   style_loss:  50752.234   content_loss:  90441.69\n",
            "best: iteration:  311 loss:  54426.29   style_loss:  50424.71   content_loss:  90440.484\n",
            "best: iteration:  313 loss:  54348.41   style_loss:  50335.14   content_loss:  90467.85\n",
            "best: iteration:  314 loss:  54001.86   style_loss:  49951.65   content_loss:  90453.766\n",
            "best: iteration:  315 loss:  53686.582   style_loss:  49599.72   content_loss:  90468.35\n",
            "best: iteration:  316 loss:  53589.477   style_loss:  49490.29   content_loss:  90482.164\n",
            "best: iteration:  317 loss:  53522.51   style_loss:  49417.18   content_loss:  90470.5\n",
            "best: iteration:  318 loss:  53319.86   style_loss:  49189.504   content_loss:  90493.07\n",
            "best: iteration:  319 loss:  53069.55   style_loss:  48911.547   content_loss:  90491.61\n",
            "best: iteration:  320 loss:  52885.6   style_loss:  48706.938   content_loss:  90493.586\n",
            "best: iteration:  321 loss:  52743.125   style_loss:  48546.742   content_loss:  90510.58\n",
            "best: iteration:  322 loss:  52589.883   style_loss:  48377.242   content_loss:  90503.67\n",
            "best: iteration:  323 loss:  52440.074   style_loss:  48209.344   content_loss:  90516.63\n",
            "best: iteration:  324 loss:  52296.78   style_loss:  48049.305   content_loss:  90524.06\n",
            "best: iteration:  325 loss:  52124.004   style_loss:  47857.508   content_loss:  90522.46\n",
            "best: iteration:  326 loss:  51927.984   style_loss:  47638.25   content_loss:  90535.6\n",
            "best: iteration:  327 loss:  51762.152   style_loss:  47453.848   content_loss:  90536.91\n",
            "best: iteration:  328 loss:  51646.742   style_loss:  47325.105   content_loss:  90541.46\n",
            "best: iteration:  329 loss:  51535.88   style_loss:  47200.79   content_loss:  90551.664\n",
            "best: iteration:  330 loss:  51386.96   style_loss:  47035.375   content_loss:  90551.234\n",
            "best: iteration:  331 loss:  51216.566   style_loss:  46845.195   content_loss:  90558.89\n",
            "best: iteration:  332 loss:  51058.805   style_loss:  46669.18   content_loss:  90565.41\n",
            "best: iteration:  333 loss:  50919.69   style_loss:  46514.742   content_loss:  90564.25\n",
            "best: iteration:  334 loss:  50784.08   style_loss:  46362.812   content_loss:  90575.48\n",
            "best: iteration:  335 loss:  50646.78   style_loss:  46210.258   content_loss:  90575.484\n",
            "best: iteration:  336 loss:  50518.64   style_loss:  46067.33   content_loss:  90580.47\n",
            "best: iteration:  337 loss:  50399.773   style_loss:  45934.383   content_loss:  90588.28\n",
            "best: iteration:  338 loss:  50277.3   style_loss:  45798.555   content_loss:  90586.02\n",
            "best: iteration:  339 loss:  50143.094   style_loss:  45648.15   content_loss:  90597.625\n",
            "best: iteration:  340 loss:  50003.246   style_loss:  45492.84   content_loss:  90596.91\n",
            "best: iteration:  341 loss:  49868.887   style_loss:  45342.867   content_loss:  90603.086\n",
            "best: iteration:  342 loss:  49741.71   style_loss:  45200.96   content_loss:  90608.47\n",
            "best: iteration:  343 loss:  49615.47   style_loss:  45060.594   content_loss:  90609.32\n",
            "best: iteration:  344 loss:  49487.785   style_loss:  44917.895   content_loss:  90616.8\n",
            "best: iteration:  345 loss:  49361.598   style_loss:  44777.492   content_loss:  90618.555\n",
            "best: iteration:  346 loss:  49241.344   style_loss:  44643.426   content_loss:  90622.625\n",
            "best: iteration:  347 loss:  49125.977   style_loss:  44514.65   content_loss:  90627.92\n",
            "best: iteration:  348 loss:  49011.156   style_loss:  44386.984   content_loss:  90628.72\n",
            "best: iteration:  349 loss:  48895.812   style_loss:  44258.117   content_loss:  90635.09\n",
            "best: iteration:  350 loss:  48781.586   style_loss:  44130.89   content_loss:  90637.83\n",
            "best: iteration:  351 loss:  48672.047   style_loss:  44008.816   content_loss:  90641.15\n",
            "best: iteration:  352 loss:  48568.555   style_loss:  43893.133   content_loss:  90647.34\n",
            "best: iteration:  353 loss:  48471.61   style_loss:  43785.457   content_loss:  90647.01\n",
            "best: iteration:  354 loss:  48384.26   style_loss:  43687.47   content_loss:  90655.4\n",
            "best: iteration:  355 loss:  48315.77   style_loss:  43611.535   content_loss:  90653.914\n",
            "best: iteration:  356 loss:  48283.105   style_loss:  43574.355   content_loss:  90661.87\n",
            "best: iteration:  381 loss:  47881.64   style_loss:  43131.01   content_loss:  90637.3\n",
            "best: iteration:  386 loss:  47811.215   style_loss:  43049.793   content_loss:  90664.03\n",
            "best: iteration:  390 loss:  46637.445   style_loss:  41741.395   content_loss:  90701.89\n",
            "best: iteration:  395 loss:  46429.516   style_loss:  41509.18   content_loss:  90712.54\n",
            "best: iteration:  399 loss:  45448.984   style_loss:  40418.984   content_loss:  90719.0\n",
            "best: iteration:  404 loss:  44938.906   style_loss:  39850.242   content_loss:  90736.87\n",
            "best: iteration:  408 loss:  44688.215   style_loss:  39569.586   content_loss:  90755.88\n",
            "best: iteration:  409 loss:  44421.76   style_loss:  39273.406   content_loss:  90756.95\n",
            "best: iteration:  413 loss:  44205.33   style_loss:  39031.434   content_loss:  90770.375\n",
            "best: iteration:  414 loss:  43875.477   style_loss:  38664.953   content_loss:  90770.195\n",
            "best: iteration:  418 loss:  43868.586   style_loss:  38655.836   content_loss:  90783.34\n",
            "best: iteration:  419 loss:  43490.74   style_loss:  38235.535   content_loss:  90787.56\n",
            "best: iteration:  420 loss:  43347.316   style_loss:  38075.15   content_loss:  90796.84\n",
            "best: iteration:  424 loss:  43240.78   style_loss:  37955.63   content_loss:  90807.14\n",
            "best: iteration:  425 loss:  42995.902   style_loss:  37683.75   content_loss:  90805.27\n",
            "best: iteration:  426 loss:  42831.48   style_loss:  37501.04   content_loss:  90805.48\n",
            "best: iteration:  427 loss:  42780.05   style_loss:  37442.38   content_loss:  90819.11\n",
            "best: iteration:  430 loss:  42712.855   style_loss:  37368.78   content_loss:  90809.54\n",
            "best: iteration:  431 loss:  42578.688   style_loss:  37217.234   content_loss:  90831.77\n",
            "best: iteration:  432 loss:  42416.68   style_loss:  37038.656   content_loss:  90818.88\n",
            "best: iteration:  433 loss:  42267.902   style_loss:  36871.977   content_loss:  90831.25\n",
            "best: iteration:  434 loss:  42157.855   style_loss:  36749.76   content_loss:  90830.7\n",
            "best: iteration:  435 loss:  42090.21   style_loss:  36674.734   content_loss:  90829.47\n",
            "best: iteration:  436 loss:  42051.516   style_loss:  36630.453   content_loss:  90841.09\n",
            "best: iteration:  437 loss:  42021.383   style_loss:  36598.227   content_loss:  90829.82\n",
            "best: iteration:  438 loss:  41985.547   style_loss:  36556.17   content_loss:  90849.914\n",
            "best: iteration:  439 loss:  41934.848   style_loss:  36501.766   content_loss:  90832.586\n",
            "best: iteration:  440 loss:  41868.406   style_loss:  36425.266   content_loss:  90856.68\n",
            "best: iteration:  441 loss:  41791.0   style_loss:  36341.438   content_loss:  90837.05\n",
            "best: iteration:  442 loss:  41710.375   style_loss:  36249.133   content_loss:  90861.58\n",
            "best: iteration:  443 loss:  41637.453   style_loss:  36170.336   content_loss:  90841.51\n",
            "best: iteration:  444 loss:  41589.562   style_loss:  36114.336   content_loss:  90866.61\n",
            "best: iteration:  514 loss:  41368.96   style_loss:  35858.156   content_loss:  90966.23\n",
            "best: iteration:  518 loss:  40788.234   style_loss:  35214.625   content_loss:  90950.7\n",
            "best: iteration:  519 loss:  39892.887   style_loss:  34218.03   content_loss:  90966.61\n",
            "best: iteration:  524 loss:  39551.93   style_loss:  33837.25   content_loss:  90984.07\n",
            "best: iteration:  545 loss:  38165.242   style_loss:  32290.473   content_loss:  91038.2\n",
            "best: iteration:  546 loss:  37854.793   style_loss:  31943.875   content_loss:  91053.08\n",
            "best: iteration:  557 loss:  37695.195   style_loss:  31765.193   content_loss:  91065.21\n",
            "best: iteration:  558 loss:  37407.32   style_loss:  31448.902   content_loss:  91033.086\n",
            "best: iteration:  559 loss:  37366.98   style_loss:  31399.564   content_loss:  91073.73\n",
            "best: iteration:  596 loss:  36910.07   style_loss:  30886.543   content_loss:  91121.805\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}